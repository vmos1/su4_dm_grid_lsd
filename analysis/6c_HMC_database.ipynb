{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to compare different runs varying coupling constants\n",
    "## Gather Plaquette, polyakov loop and Acceptance \n",
    "Author: Venkitesh Ayyar (vayyar@bu.edu) \\\n",
    "May 4, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import subprocess as sp\n",
    "import os \n",
    "import glob\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import yaml\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gvar as gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('modules')\n",
    "from modules_parse_hmc_Grid import *\n",
    "from modules_measurement import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ \\chi_\\mathcal{O} = L^3 \\left[ \\langle \\mathcal{O}^2 \\rangle - {(\\langle \\mathcal{O} \\rangle )}^2 \\right] = L^3 \\langle (\\mathcal{O} - \\bar{\\mathcal{O}})^2\\rangle $$ \n",
    "\n",
    "$$ \\kappa_\\mathcal{O} = \\frac{\\langle \\mathcal{O}^4 \\rangle - 4 \\langle \\mathcal{O}^3 \\rangle \\langle \\mathcal{O} \\rangle +6 \\langle \\mathcal{O}^2 \\rangle {\\langle \\mathcal{O} \\rangle} ^2 - 3 {\\langle \\mathcal{O} \\rangle}^4 }{\\chi_\\mathcal{O}^2} = \\frac{ \\langle \\left( \\mathcal{O-\\bar{\\mathcal{O}}} \\right) ^4 \\rangle }{\\chi_\\mathcal{O}^2}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_run_info_dict(dict1,input_dict,run_label):\n",
    "    '''   \n",
    "    Get dictionary with run info that will be added to Dataframe as columns\n",
    "    '''\n",
    "    keys=['Lx','Lt','beta','mf']\n",
    "    for key in keys:\n",
    "        dict1[key]=input_dict[key]\n",
    "    \n",
    "    run_key='beta-%s_mf-%s_Lx-%s_Lt-%s'%(input_dict['beta'],input_dict['mf'],input_dict['Lx'],input_dict['Lt'])\n",
    "    \n",
    "    if input_dict['F_action'] =='Mobius_dwf': ## Add Ls in label for DWF\n",
    "        keys.append('dwf_Ls')\n",
    "    \n",
    "        \n",
    "    run_key='beta-%s_mf-%s_Lx-%s_Lt-%s'%(input_dict['beta'],input_dict['mf'],input_dict['Lx'],input_dict['Lt'])\n",
    "            \n",
    "    if input_dict['F_action'] =='Mobius_dwf': ## Add Ls in label for DWF\n",
    "        run_key+='_Ls-%s'%(input_dict['dwf_Ls'])\n",
    "\n",
    "    dict1['run_label'] = run_label\n",
    "    run_key+='_'+run_label \n",
    "    \n",
    "    dict1['run_key']   = run_key\n",
    "        \n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_write_hmc_details_to_dbase(conn,Lx,Lt,top_dir,run_label):\n",
    "    '''\n",
    "    Combine results from different run extensions for a single run\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    fldr_list=glob.glob(top_dir+'run_Lx-%s_Lt-%s*'%(Lx,Lt))[:5]\n",
    "\n",
    "    for run_fldr in fldr_list: \n",
    "        print(run_fldr)\n",
    "        # Read config file from folder\n",
    "        input_dict=f_read_config(run_fldr+'/config.yaml')\n",
    "\n",
    "        # Extract info from HMC output \n",
    "        flist=glob.glob(run_fldr+'/HSDM?.out')\n",
    "        if len(flist)<1:    \n",
    "            print(\"Not file HSDM*.out in %s\"%(run_fldr))\n",
    "            continue\n",
    "\n",
    "        # sort output file list sequentially\n",
    "        flist=[file_name.split('HSDM')[0]+'HSDM%s.out'%(i+1) for i,file_name in enumerate(flist)]\n",
    "\n",
    "        ## Sum results from successive runs\n",
    "        for idx,fname in enumerate(flist):\n",
    "\n",
    "            try : \n",
    "                dict1={}\n",
    "                df_a=f_parse_grid_data(fname)\n",
    "                \n",
    "                ## Add run data as columns of dataframe\n",
    "                dict1=f_get_run_info_dict(dict1,input_dict,run_label)\n",
    "                for key in dict1:\n",
    "                    df_a[key]=dict1[key]\n",
    "                                    \n",
    "            except Exception as e:\n",
    "                print(e,fname)\n",
    "                continue\n",
    "\n",
    "            if idx==0:\n",
    "                print(\"idx\",idx,fname)\n",
    "                df=df_a.copy()\n",
    "            else : \n",
    "                df=f_merge_df_successive_runs(df,df_a)\n",
    "                \n",
    "        # sqlite can't handle complex types, so convert to string\n",
    "        df['Polyakov']=df['Polyakov'].astype(str)\n",
    "        print(df.shape)\n",
    "#         display(df)\n",
    "        df.to_sql('test',conn,if_exists='append',index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write hmc data to sql database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__==\"__main__\" : \n",
    "    \n",
    "    # Write data to sql database\n",
    "    fname1='Stored_data/sql_dbase_files/parsed_hmc.db'\n",
    "    \n",
    "    if os.path.exists(fname1):\n",
    "        os.remove(fname1)\n",
    "    conn = sqlite3.connect(fname1)\n",
    "\n",
    "    df_summary=pd.DataFrame([])\n",
    "    top_dir='/usr/workspace/lsd/ayyar1/projects/SU4_sdm/runs_Grid/2023_july12/runs/phase_diagram_5_hot_start/'\n",
    "    f_write_hmc_details_to_dbase(conn,Lx='*',Lt='*',top_dir=top_dir,run_label='hot-start')\n",
    "\n",
    "    top_dir='/usr/workspace/lsd/ayyar1/projects/SU4_sdm/runs_Grid/2023_july12/runs/phase_diagram_4_cold_start/'\n",
    "    f_write_hmc_details_to_dbase(conn,Lx='*',Lt='*',top_dir=top_dir,run_label='cold-start')\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Read sql database\n",
    "\n",
    "# fname1='Stored_data/sql_dbase_files/parsed_hmc.db'\n",
    "# conn = sqlite3.connect(fname1)\n",
    "# df_read=pd.read_sql_query(\"SELECT * FROM test\",conn)\n",
    "# df_read['Polyakov']=df_read['Polyakov'].astype(np.complex128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read sql database\n",
    "\n",
    "def f_read_hmc_raw(fname):\n",
    "    conn = sqlite3.connect(fname)\n",
    "    df=pd.read_sql_query(\"SELECT * FROM test\",conn)\n",
    "    df['Polyakov']=df['Polyakov'].astype(np.complex128)\n",
    "    conn.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write summary data to sql dbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__==\"__main__\" : \n",
    "    \n",
    "    ### Read in hmc data\n",
    "    fname1='Stored_data/sql_dbase_files/parsed_hmc.db'\n",
    "    df_read = f_read_hmc_raw(fname1)\n",
    "    \n",
    "    \n",
    "    ### Create summary Dataframe\n",
    "    df_summary=pd.DataFrame([])\n",
    "    run_keys=np.unique(df_read.run_key.values)\n",
    "\n",
    "    for rk in run_keys: # iterate over each ensemble\n",
    "        df=df_read[df_read.run_key==rk].reset_index()\n",
    "\n",
    "        equil = max(80,int(df.shape[0]*0.5))\n",
    "        dict2={}\n",
    "        for key in ['beta','mf','Lx','Lt','run_key','run_label']:\n",
    "            dict2[key] = np.unique(df[key].values)[0]\n",
    "\n",
    "        dict2=f_get_summary_data(df,dict2['Lx'],dict2,equil)\n",
    "        df_summary=pd.concat([df_summary,pd.DataFrame(dict2,index=[df_summary.shape[0]+1])])  \n",
    "\n",
    "    # Drop rows with no values\n",
    "    df_summary=df_summary.sort_values(by=['beta','mf']).reset_index(drop=True)\n",
    "\n",
    "    # Traj l = 2, so num_conf is twice the value\n",
    "    df_summary['num_conf']=df_summary['num_conf']*2\n",
    "    \n",
    "    \n",
    "    ### Write summary df to sql dbase\n",
    "    # Convert gvars to strings for storing in Dataframe\n",
    "    gvar_key_list=['plaq', 'sus_plaq', 'kurt_plaq', 'polyakov', 'sus_poly', 'kurt_poly', 'traj_time']\n",
    "    for key in gvar_key_list:     df_summary[key]=df_summary[key].astype(str)\n",
    "    \n",
    "    fname2='Stored_data/sql_dbase_files/summary_hmc_data.db'\n",
    "    \n",
    "    if os.path.exists(fname2):\n",
    "        os.remove(fname2)\n",
    "    \n",
    "    conn = sqlite3.connect(fname2)\n",
    "    df_summary.to_sql('summary',conn,if_exists='replace',index=False)\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read sql database\n",
    "fname2='Stored_data/sql_dbase_files/summary_hmc_data.db'\n",
    "conn = sqlite3.connect(fname2)\n",
    "df_summary_2=pd.read_sql_query(\"SELECT * FROM summary\",conn)\n",
    "\n",
    "\n",
    "# Convert strings to gvars for analysis\n",
    "gvar_key_list=['plaq', 'sus_plaq', 'kurt_plaq', 'polyakov', 'sus_poly', 'kurt_poly', 'traj_time']\n",
    "for key in gvar_key_list:    \n",
    "    df_summary_2[key] = df_summary_2[key].apply(lambda x: gv.gvar(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v38",
   "language": "python",
   "name": "vpy38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
